{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19a293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**DISCLAIMER**\n",
      "Do not use this prediction for self-diagnosis. You should check with your local authorities for the latest advice on seeking medical assistance.\n"
     ]
    }
   ],
   "source": [
    "# Build a batch script around 'inference.py'\n",
    "# Function of importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, argparse\n",
    "import cv2\n",
    "from data import process_image_file\n",
    "\n",
    "class Inference(object):\n",
    "    def __init__(self, weightspath, metaname, ckptname, input_size=480, n_classes=3, top_percent=0.08,\n",
    "                 in_tensorname='input_1:0', out_tensorname='norm_dense_2/Softmax:0',is_severity_model=False):\n",
    "        \"\"\"\n",
    "        weightspath: the path to the directory holding the pretrained model\n",
    "        metaname: Name of ckpt meta file\n",
    "        ckptname: Name of model ckpts\n",
    "        imagepath: path to the image to run through the model\n",
    "        \"\"\"\n",
    "        self.weightspath = weightspath\n",
    "        self.metaname=metaname\n",
    "        self.ckptname = ckptname\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        self.top_percent = top_percent\n",
    "        self.in_tensorname = in_tensorname\n",
    "        self.out_tensorname = out_tensorname\n",
    "        self.is_severity_model = is_severity_model\n",
    "    \n",
    "    def visualise_graph(self):\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            saver = tf.compat.v1.train.import_meta_graph(os.path.join(self.weightspath, self.metaname))\n",
    "            saver.restore(sess, os.path.join(self.weightspath, self.ckptname))\n",
    "            graph = tf.compat.v1.get_default_graph()\n",
    "            tensors = [t.name for op in graph.get_operations() for t in op.values()]\n",
    "            for t in tensors:\n",
    "                print(t)\n",
    "    \n",
    "    def execute(self, imagepath_or_directory, verbose=False):\n",
    "        # To remove TF Warnings\n",
    "        tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "        \n",
    "        if self.is_severity_model:\n",
    "            # For COVIDNet CXR-S training with COVIDxSev level 1 and level 2 air space seveirty grading\n",
    "            mapping = {'level2': 0, 'level1': 1}\n",
    "            inv_mapping = {0: 'level2', 1: 'level1'}\n",
    "        elif self.n_classes == 2:\n",
    "            # For COVID-19 positive/negative detection\n",
    "            mapping = {'negative': 0, 'positive': 1}\n",
    "            inv_mapping = {0: 'negative', 1: 'positive'}\n",
    "        elif self.n_classes == 3:\n",
    "            # For detection of no pneumonia/non-COVID-19 pneumonia/COVID-19 pneumonia\n",
    "            mapping = {'normal': 0, 'pneumonia': 1, 'COVID-19': 2}\n",
    "            inv_mapping = {0: 'normal', 1: 'pneumonia', 2: 'COVID-19'}\n",
    "        else:\n",
    "            raise Exception('''COVID-Net currently only supports 2 class COVID-19 positive/negative detection\n",
    "                or 3 class detection of no pneumonia/non-COVID-19 pneumonia/COVID-19 pneumonia''')\n",
    "        \n",
    "        # Tensorflow\n",
    "        mapping_keys = list(mapping.keys())\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            saver = tf.compat.v1.train.import_meta_graph(os.path.join(self.weightspath, self.metaname))\n",
    "            saver.restore(sess, os.path.join(self.weightspath, self.ckptname))\n",
    "            graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "            image_tensor = graph.get_tensor_by_name(self.in_tensorname)\n",
    "            pred_tensor = graph.get_tensor_by_name(self.out_tensorname)\n",
    "            \n",
    "            # Images to be processed are input here\n",
    "            if os.path.isdir(imagepath_or_directory):\n",
    "                imagepaths_list = self.imagepaths(imagepath_or_directory)\n",
    "            else:\n",
    "                imagepaths_list = [imagepath_or_directory]\n",
    "            \n",
    "            # Predictionss\n",
    "            preds_list = []\n",
    "            for imagepath in imagepaths_list:\n",
    "                x = process_image_file(imagepath, self.top_percent, self.input_size)\n",
    "                x = x.astype('float32') / 255.0\n",
    "                pred = sess.run(pred_tensor, feed_dict={image_tensor: np.expand_dims(x, axis=0)})\n",
    "                preds_list.append(pred[0])\n",
    "                if verbose:\n",
    "                    print('Prediction: {}'.format(inv_mapping[pred.argmax(axis=1)[0]]))\n",
    "                    print('Confidence')\n",
    "                    print(' '.join('{}: {:.3f}'.format(cls.capitalize(), pred[0][i]) for cls, i in mapping.items()))\n",
    "            preds_list = np.vstack(preds_list)\n",
    "        return preds_list\n",
    "    \n",
    "    ## Set up imagepaths\n",
    "    def imagepaths(self, directory):\n",
    "        path_list = []\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for name in files:\n",
    "                if '.png' in name:\n",
    "                    path_list.append(os.path.join(root, name))\n",
    "        return path_list\n",
    "        \n",
    "    \n",
    "    def reset_graph(self):\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "    def visualise_image(self, imagepath):\n",
    "        x = process_image_file(imagepath, self.top_percent, self.input_size)\n",
    "        print(\"Image size: \" + str(x.shape))\n",
    "        plt.imshow(x)\n",
    "        return\n",
    "\n",
    "print('**DISCLAIMER**')\n",
    "print('Do not use this prediction for self-diagnosis. You should check with your local authorities for the latest advice on seeking medical assistance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f384d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = Inference(weightspath=\"CXR4-A/\", metaname=\"model.meta\", ckptname=\"model-18540\",\n",
    "                in_tensorname='input_1:0', out_tensorname='norm_dense_1/Softmax:0')\n",
    "# External PolyU\n",
    "non_suppressed_directory_HK = \"D:/data/POLYU_COVID19_CXR_CT_Cohort1/cxr/CXR_PNG\"\n",
    "suppressed_Rajaraman_HK = \"../Rajaraman_ResNet_BS/bone_suppressed/external_POLYU/\"\n",
    "suppressed_Gusarev_HK = \"../Deep-Learning-Models-for-bone-suppression-in-chest-radiographs/bone_suppressed/external_POLYU/\"\n",
    "\n",
    "# JSRT External\n",
    "non_suppressed_directory_JSRT = \"D:/data/JSRT/JSRT/\"\n",
    "suppressed_Rajaraman_JSRT =  \"../Rajaraman_ResNet_BS/bone_suppressed/internal_original/\"\n",
    "suppressed_Gusarev_JSRT =  \"../Deep-Learning-Models-for-bone-suppression-in-chest-radiographs/bone_suppressed/internal_original/\"\n",
    "# JSRT Non-nodule\n",
    "non_suppressed_directory_JSRT_NN = \"D:/data/JSRT/JSRT_NN/\"\n",
    "suppressed_Rajaraman_JSRT_NN =  \"../Rajaraman_ResNet_BS/bone_suppressed/internal_NN/\"\n",
    "\n",
    "preds = inf.execute(non_suppressed_directory_JSRT_NN, verbose=False)\n",
    "\n",
    "inf.reset_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c19003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion classed as normal: 0.24731182795698925\n",
      "Proportion classed as pneumonia: 0.053763440860215055\n",
      "Proportion classed as COVID: 0.6989247311827957\n"
     ]
    }
   ],
   "source": [
    "idx_normal = np.logical_and( preds[:,0] > preds[:,1] , preds[:,0] > preds[:,2])\n",
    "idx_pneumonia = np.logical_and( preds[:,1] > preds[:,0] , preds[:,1] > preds[:,2])\n",
    "idx_COVID = np.logical_and( preds[:,2] > preds[:,1] , preds[:,2] > preds[:,0])\n",
    "\n",
    "print(\"Proportion classed as normal: \" +str(np.sum(idx_normal)/len(idx_normal)))\n",
    "print(\"Proportion classed as pneumonia: \" +str(np.sum(idx_pneumonia)/len(idx_pneumonia)))\n",
    "print(\"Proportion classed as COVID: \" +str(np.sum(idx_COVID)/len(idx_COVID)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
